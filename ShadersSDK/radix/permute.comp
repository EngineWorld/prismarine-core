#version 460 core
#include "./includes.glsl"

//layout (local_size_x = WARP_SIZE, local_size_y = WORK_SIZE) in;
layout (local_size_x = BLOCK_SIZE) in;

#define LOCAL_SORT_SIZE (WORK_SIZE*RADICES)

shared uint localSort[LOCAL_SORT_SIZE];
shared uint localHistogramToCarry[RADICES];
shared uint localHistogram[RADICES];
shared uint bcount;

void prefixScan(){
    UVEC_WARP localIdx = LT_IDX;
    memoryBarrier(); barrier();
    uint tmp = localIdx >= 1 && localIdx < RADICES ? localHistogram[localIdx-1] : 0;
    memoryBarrier(); barrier();
    if (localIdx < RADICES) localHistogram[localIdx] = tmp;

    // reduction prefix-scan
    for (int i=1;i<RADICES;i<<=1) {
        memoryBarrier(); barrier();
        uint idx = localIdx;
        uint off = idx >= i && idx < RADICES ? localHistogram[idx-i] : 0;
        uint hst = idx < RADICES ? localHistogram[idx] : 0;
        memoryBarrier(); barrier();
        if (idx < RADICES) localHistogram[idx] = off + hst;
    }
    memoryBarrier(); barrier();
}

void main(){
    LT_IDX = gl_LocalInvocationID.x;
    LC_IDX = (gl_LocalInvocationID.x / gl_SubGroupSizeARB);
    LANE_IDX = (gl_LocalInvocationID.x % gl_SubGroupSizeARB);

    blocks_info blocks = get_blocks_info(NumKeys);
    UVEC_WARP localIdx = LT_IDX;
    if (localIdx < RADICES) localHistogram[localIdx] = Histogram[localIdx + gl_WorkGroupID.x * RADICES];
    if (localIdx == 0) bcount = min(blocks.count, 4096);
    memoryBarrier(); barrier(); 
    
    // do permuration
    UVEC_WARP addr = blocks.offset + localIdx;
    if (localIdx < RADICES) localHistogramToCarry[localIdx] = localHistogram[localIdx];
    for ( int wk=0; wk < bcount; wk++ ) { // permute
        if (anyInvocation(wk >= bcount)) break;
        if (wk < bcount) {
            BVEC_WARP validAddress = addr < NumKeys;
            UVEC64_WARP data       = validAddress ? UVEC64_WARP(KeyTmp[addr]) : 0xFFFFFFFFFFFFFFFFul;
            UVEC_WARP dataValue    = validAddress ? ValueTmp[addr] : 0u;

            UVEC_WARP k = UVEC_WARP(BFE(data, int(Shift*BITS_PER_PASS), BITS_PER_PASS));
            UVEC_WARP      key = k;
            UVEC_WARP  histKey = key;
            UVEC_WARP localKey = key + (LT_IDX/WARP_SIZE_RT) * RADICES;

            UVEC_WARP SZ = LOCAL_SORT_SIZE > 0 ? (LOCAL_SORT_SIZE - 1) / BLOCK_SIZE_RT + 1 : 0;
            for (int i=0;i<SZ;i++) {
                uint tid = localIdx + BLOCK_SIZE_RT*i;
                if (tid < LOCAL_SORT_SIZE) localSort[tid] = 0;
            }
            memoryBarrier(); barrier();

            if (validAddress) atomicAdd(localSort[localKey], uint(validAddress));
            UVEC_WARP offset = localHistogramToCarry[k] + localIdx;

            memoryBarrier(); barrier();
            UVEC_WARP sum = 0;
            if (localIdx < RADICES) {
                for (int i=0;i<LOCAL_SORT_SIZE/RADICES;i++) sum += localSort[i * RADICES + localIdx];
                if (localIdx < RADICES) localHistogramToCarry[localIdx] += localHistogram[localIdx] = sum;
            }

            prefixScan();

            UVEC_WARP outKey = offset - localHistogram[histKey];
            if (validAddress)   KeyIn[outKey] = KEYTYPE(data);
            if (validAddress) ValueIn[outKey] = dataValue;
            memoryBarrier(); barrier();

            addr += BLOCK_SIZE_RT * gl_NumWorkGroups.x;
        }
    }
    
}
